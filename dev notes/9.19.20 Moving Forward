Next steps:* Testing: 	* Test out more frequency shifting and make sure resonant shifts sound good	* Research more ways to make shifted frequency audio sound better when a 	  lot of bands move* First round of features (set in stone):	* Formant estimation using LPC	* Graphics display for formant estimation	* Optional Frequency and Time grid overlay* To think about:	Frequency shifting algorithms that take formants into account	* 2nd round of features (Not set in stone):	* Automatic detection of frequency shifts to vocal mechanics	* And/or implementing frequency shifts from a selection of vocal mechanics	* And/or implementing shifts based on a specific sound desired	* Intuitive user interface for these features (**very important**)		* Resonance and voice makes no sense to about 80%+ of people 		  Having a good UI that is explanatory is important	* What would this potential UI look like? 		* Each option should ideally come with a sample demonstration		  i.e. raising larynx corresponding with a visual aide of what that		  corresponds to on the spectrogram while also providing in app audio		  of what that change sounds like	* In app tutorials and demonstrations are going to be important here	!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!	* What about ways to detect weaknesses in resonance?		* Ex. The app asks you to say a vowel or a word. I then use		  prediction to calculate expected formants of that sound, calculate		  the deviation from that sound, and then provide feedback on that		  sound? That would be even easier + gives direct feedback			This is a really good idea and I think not too hard			to implement!		* Also provide ways to gameify it for the user, making it fun!			* Potentially track progress? Not 1.0, but 2.0?I'm a really big fan of the brainstormed ideas at the end. I also think I'mfacing a problem of feature creep. v0.5 has everything I set out to make amonth ago. This was the ~original~ v1.0. But I don't think I would feelsatisfied calling this a final product unless I have ways to provide feedbackon resonance to the user. This app means NOTHING if it doesn't provide easy andintuitive ways for people not knowledgable in voice to improve their voice.My dream: for a trans person to pick up this app, know nothing about voice, andstart improving right away. That will be v1.0. As of right now, my project isnot there. I think, the 2nd round of features outlined (most specifically the"!!!" marked section), will provide that opportunity. That being said, the **important** DSP features I set out to include that I'vewanted in spectrograms are now included. Now it's onward to making this apphelp OTHERS. 	